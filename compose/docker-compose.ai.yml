services:

  ai:
    container_name: ${COMPOSE_PROJECT_NAME:-bluespice}-ai
    image: ${BLUESPICE_SERVICE_REPOSITORY}/ai:${VERSION}
    depends_on:
      - ai-database
    environment:
      AI__MYSQL__USER: ${DB_USER}
      AI__MYSQL__PASSWORD: ${DB_PASS}
      AI__MYSQL__HOST: ${DB_HOST}
      AI__MYSQL__DB_NAME: ${DB_NAME}
      AI__NEO4J__USERNAME: neo4j
      AI__NEO4J__PASSWORD: ${AI_DB_PASS}
      AI__NEO4J__URL: neo4j://ai-database:7687
      AI__NEO4J__DATABASE: ${AI_DB_NAME:-bluespice}
      # when embedder is not specified, the llm provider will be used
      # AI__EMBEDDER_PROVIDER: ${EMBEDDER_PROVIDER} # azure, google, ionos, ollama, openai
      AI__LLM_PROVIDER: ${LLM_PROVIDER} # azure, google, ionos, ollama, openai
      AI__AZURE__REGION: ${AZURE_REGION:-westeurope}
      AI__AZURE__OPENAI_API_KEY: ${AZURE_OPENAI_API_KEY:-}
      AI__AZURE__OPENAI_ENDPOINT: ${AZURE_OPENAI_ENDPOINT:-}
      AI__GOOGLE__API_KEY: ${GOOGLE_API_KEY:-}
      AI__IONOS__API_KEY: ${IONOS_API_KEY:-}
      AI__IONOS__BASE_URL: ${IONOS_BASE_URL:-https://openai.inference.de-txl.ionos.com}
      AI__OPENAI__API_KEY: ${OPENAI_API_KEY:-}
      AI__OLLAMA__URL: ${OLLAMA_URL:-}
      AI__OLLAMA__EMBEDDING_MODEL: ${OLLAMA_EMBEDDING_MODEL:-mxbai-embed-large:335m}
      AI__OLLAMA__MODEL: ${OLLAMA_LLM_MODEL:-llama3.3}
    secrets:
      - AI__SECURITY__STATIC_API_TOKEN
    volumes:
      - ${DATADIR}/wiki/bluespice/rag:/watch
    restart: unless-stopped

  ai-database:
    container_name: ${COMPOSE_PROJECT_NAME:-bluespice}-ai-database
    image: neo4j:5
    depends_on: 
      wiki-task:
        condition: service_healthy
    environment:
      NEO4J_AUTH: neo4j/${AI_DB_PASS}
    volumes:
      - ${DATADIR}/ai-data:/data

  chat:
    depends_on:
      - ai
    environment:
      CHAT_AI_CHAT_SERVICE_URL: http://ai:8000
    secrets:
      - CHAT_AI_CHAT_SERVICE_API_KEY
